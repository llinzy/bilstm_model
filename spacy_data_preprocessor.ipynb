{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing for neural network using GloVe embedding\n",
    "#preprocessing packages\n",
    "import pandas as pd\n",
    "from nltk.stem import SnowballStemmer\n",
    "import re\n",
    "import glob\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "spacy.require_gpu()\n",
    "nlp = en_core_web_sm.load()\n",
    "stemmer=SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalist=glob.glob('/home/kysha/occ_combined/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_datalist=[pd.read_csv(i) for i in datalist] \n",
    "combined_datalist=pd.concat([pd.DataFrame(combined_datalist[i]) for i in range(len(combined_datalist))], ignore_index=True)\n",
    "rec_data=combined_datalist[['skill_category','skill_title','job_description','city','state']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'skill_title', 'job_title', 'job_description', 'city',\n",
       "       'state', 'links', 'skill_category', 'skill_class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_datalist.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('stopwords.txt', 'r') as f:\n",
    "    word=f.read().split('\\n')\n",
    "\n",
    "word=word\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_remove_emails_https(X_data):\n",
    "    X_t=[]\n",
    "    for i in X_data:\n",
    "        X_t.append(''.join([p.replace('\\n',' ').replace('>','')\\\n",
    "                            .replace('<','').replace('-',' ') for p in str(i)]))\n",
    "        \n",
    "    #remove emails and http(s) streams - can be removed\n",
    "    collection=[]\n",
    "    for i in X_t:\n",
    "        collection.append(re.findall(r'[A-Za-z0-9_.\\-@+]{8,30}edu|[A-Za-z0-9._\\-@+]{8,30}com|[A-Za-z0-9_.\\-@+]{8,30}gov|[A-Za-z0-9_.\\-@+]{8,30}net|http://[a-z0-9_.\\-@+]{8,150}|https://[a-z0-9_.\\-@+]{8,150}', str(i)))\n",
    "    \n",
    "    X_emails__http_rm=[]\n",
    "    for i,j in zip(X_t,collection):\n",
    "        X_emails__http_rm.append(' '.join([p.lower() for p in i.split() if p not in j]))\n",
    "        \n",
    "    return X_emails__http_rm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 24s, sys: 144 ms, total: 1min 24s\n",
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = rec_data.job_description\n",
    "X_emails__http_rm_data=clean_remove_emails_https(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nouns_verbs_only(data):\n",
    "    words_with_pos=[]\n",
    "    for i in data:\n",
    "        words_with_pos.append([[k.text, k.pos_] for k in nlp(i)])\n",
    "    \n",
    "    nouns_verbs_only=[]\n",
    "    for i in words_with_pos:\n",
    "        wrds=[k[0] for k in i]\n",
    "        pos=[k[1] for k in i]\n",
    "        df=pd.concat([pd.Series(wrds, name='words'),pd.Series(pos, name='pos')], axis=1)\n",
    "        df=df[(df.pos=='NOUN')|(df.pos=='VERB')].reset_index().iloc[:,1:]\n",
    "        nouns_verbs_only.append(df)\n",
    "        \n",
    "    nouns_verb_only_text=[list(i.words) for i in nouns_verbs_only]\n",
    "    \n",
    "       \n",
    "    return nouns_verb_only_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nouns_only(data):\n",
    "    words_with_pos=[]\n",
    "    for i in data:\n",
    "        words_with_pos.append([[k.text, k.pos_] for k in nlp(i)])\n",
    "    \n",
    "    nouns_only=[]\n",
    "    for i in words_with_pos:\n",
    "        wrds=[k[0] for k in i]\n",
    "        pos=[k[1] for k in i]\n",
    "        df=pd.concat([pd.Series(wrds, name='words'),pd.Series(pos, name='pos')], axis=1)\n",
    "        df=df[(df.pos=='NOUN')].reset_index().iloc[:,1:]\n",
    "        nouns_only.append(df)\n",
    "        \n",
    "    nouns_only_text=[list(i.words) for i in nouns_only]\n",
    "    \n",
    "       \n",
    "    return nouns_only_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_word_pos(data):\n",
    "    words_with_pos=[]\n",
    "    for i in data:\n",
    "        words_with_pos.append([[k.text, k.pos_] for k in nlp(i)])\n",
    "    \n",
    "    all_pos=[]\n",
    "    for i in words_with_pos:\n",
    "        wrds=[k[0] for k in i]\n",
    "        pos=[k[1] for k in i]\n",
    "        df=pd.concat([pd.Series(wrds, name='words'),pd.Series(pos, name='pos')], axis=1)\n",
    "        df=df.reset_index().iloc[:,1:]\n",
    "        all_pos.append(df)\n",
    "        \n",
    "    #can subset df after run to focus desired positions\n",
    "    return all_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28min 38s, sys: 3.91 s, total: 28min 42s\n",
      "Wall time: 28min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#28 mins 56,003 rows data & Spacy GPU required (4 GPUs)\n",
    "nouns_verb_only_text=nouns_only(X_emails__http_rm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_stopword_stem_word_cnt(data):\n",
    "       \n",
    "    no_stopwords=[]\n",
    "    for i in data:\n",
    "        no_stopwords.append(' '.join([j for j in i if j not in word and len(j) >=3]))\n",
    "        \n",
    "    no_stop_stemmed_words=[]\n",
    "    for p in no_stopwords:\n",
    "        no_stop_stemmed_words.append(' '.join([stemmer.stem(k) for k in p.split()]))\n",
    "    \n",
    "    data_len=[]\n",
    "    for i in no_stop_stemmed_words:\n",
    "        data_len.append(len(i.split()))\n",
    "        \n",
    "    return no_stop_stemmed_words,data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 35s, sys: 12 ms, total: 2min 35s\n",
      "Wall time: 2min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "no_stop_stemmed=rm_stopword_stem_word_cnt(nouns_verb_only_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kysha/anaconda3/envs/kyshaenv2/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/kysha/anaconda3/envs/kyshaenv2/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "rec_data['no_stopwords_stemmed']=pd.Series(no_stop_stemmed[0])\n",
    "rec_data['data_len']=pd.Series(no_stop_stemmed[1])\n",
    "rec_data=rec_data.fillna('None')\n",
    "data=rec_data[rec_data.skill_category!='None'].copy()\n",
    "data2=data[(data.data_len>0)]\n",
    "data3=data2[data2.data_len>data2.data_len.mean()].reset_index().iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skill_category</th>\n",
       "      <th>skill_title</th>\n",
       "      <th>job_description</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>no_stopwords_stemmed</th>\n",
       "      <th>data_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mathematics.xls</td>\n",
       "      <td>Mathematicians</td>\n",
       "      <td>Duties \\n Summary \\n About the Position:  This...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>duti posit posit duti locat applic level targe...</td>\n",
       "      <td>796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mathematics.xls</td>\n",
       "      <td>Mathematicians</td>\n",
       "      <td>Senior Business Analyst / Lead Business Analys...</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>busi analyst busi analyst organ group chegg gr...</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mathematics.xls</td>\n",
       "      <td>Mathematicians</td>\n",
       "      <td>Manager, Business Analytics \\nAnalytics | New ...</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>manag organ group chegg group data decis chegg...</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mathematics.xls</td>\n",
       "      <td>Mathematicians</td>\n",
       "      <td>About Mastery: \\nWe believe educational inequi...</td>\n",
       "      <td>Camden</td>\n",
       "      <td>NJ</td>\n",
       "      <td>masteri inequ problem countri right issu day m...</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mathematics.xls</td>\n",
       "      <td>Mathematicians</td>\n",
       "      <td>About Mastery: \\nWe believe educational inequi...</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>PA</td>\n",
       "      <td>masteri inequ problem countri right issu day m...</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    skill_category     skill_title  \\\n",
       "0  Mathematics.xls  Mathematicians   \n",
       "1  Mathematics.xls  Mathematicians   \n",
       "2  Mathematics.xls  Mathematicians   \n",
       "3  Mathematics.xls  Mathematicians   \n",
       "4  Mathematics.xls  Mathematicians   \n",
       "\n",
       "                                     job_description          city state  \\\n",
       "0  Duties \\n Summary \\n About the Position:  This...          None  None   \n",
       "1  Senior Business Analyst / Lead Business Analys...      New York    NY   \n",
       "2  Manager, Business Analytics \\nAnalytics | New ...      New York    NY   \n",
       "3  About Mastery: \\nWe believe educational inequi...        Camden    NJ   \n",
       "4  About Mastery: \\nWe believe educational inequi...  Philadelphia    PA   \n",
       "\n",
       "                                no_stopwords_stemmed  data_len  \n",
       "0  duti posit posit duti locat applic level targe...       796  \n",
       "1  busi analyst busi analyst organ group chegg gr...       309  \n",
       "2  manag organ group chegg group data decis chegg...       238  \n",
       "3  masteri inequ problem countri right issu day m...       211  \n",
       "4  masteri inequ problem countri right issu day m...       211  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3.to_csv('occ_preprocessed_mean_noun_only.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
