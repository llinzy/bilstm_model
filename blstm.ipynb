{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "15h7bvGCHHwS8e5-ZUFzjwkVXM4bLKQ6m",
      "authorship_tag": "ABX9TyNSQWfDS7jvCPC9wXxeinvb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/llinzy/nlp_deep_learning/blob/master/blstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7t5YuBkmfklk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import itertools\n",
        "import glob"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbnFBibNzoa6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6936b1c9-f257-4ff4-d34d-c678d47d2e13"
      },
      "source": [
        "%cd drive/My Drive/nlp_deeplearning"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/nlp_deeplearning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wc1R5wHZhKXS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "glob_1=glob.glob('nlp_deep_learning/glovesplit4/*.csv')\n",
        "glob_2=glob.glob('nlp_deep_learning/glovesplit4.2/*.csv')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X80HXeYSoiHQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "da7be35a-fc45-4516-e4ba-49624b303da8"
      },
      "source": [
        "glob_=list(itertools.chain.from_iterable([glob_1,glob_2]))\n",
        "len(glob_)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "131"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vUiiZ3nlQTE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pandas.io.parsers import ParserError"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_1vQvT5cT3x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "errors=[]\n",
        "for i in glob_:\n",
        "  try:\n",
        "    d.append(pd.read_csv(i))\n",
        "  except ParserError as error:\n",
        "    errors.append(str(error))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpNm6tOx4R6y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Avb_D3V1tv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "errors_=[int(p[0]) for p in [re.findall(r'\\d{1,6}', str(i)) for i in errors]]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiI4rs1t4vzw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d=[]\n",
        "for i in glob_:\n",
        "  d.append(pd.read_csv(i, skiprows=errors_, names=['word','values_']))  "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvFTy6vXe9sr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "97dbcf42-c695-47ac-ec3b-defc0c1af868"
      },
      "source": [
        "len(d)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiPi-kM35KEc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "glove_clean=[d[i][d[i].iloc[:,0].str.len()<20] for i in range(len(d))]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwKPlaChucwg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znlmgGGFaDKz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "75b54742-899b-4d67-e1a5-24439c7c9961"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFNXrcZEVWlT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for j in range(len(glove_clean)):\n",
        "\tglove_clean[j].to_csv(f'nlp_deep_learning/glove_clean/glove_file_{j}.csv')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmoGhZC3hlwQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLVfYLOqaJZ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDtYPoeyatgY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50JAnWUratkk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import torch\n",
        "import itertools\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn import preprocessing\n",
        "from numpy import zeros"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTr632Jba4Bo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data3=pd.read_csv('nlp_deep_learning/d_group2.csv')\n",
        "data3=data3.iloc[:,1:]\n",
        "\n",
        "data3=data3[(data3.occ_group=='technical')|(data3.occ_group=='complex problem solving')]\n",
        "\n",
        "data3=data3.drop_duplicates(keep='first')\n",
        "\n",
        "data3['occ_group']=data3['occ_group'].fillna('None')\n",
        "data3=data3[data3.occ_group!='None']"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nw6_3ICZbUnb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datalist1=glob.glob('nlp_deep_learning/glove_clean/*.csv')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TWPDib7bYg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(datalist1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldQj6RhdbeDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combined_datalist=[pd.read_csv(i) for i in datalist1]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7ix9g4yoiU0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "02fd43aa-0d34-4d4f-c83f-2851606df4c8"
      },
      "source": [
        "len(combined_datalist)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "134"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaJ9bQrRqtnF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words_=list(itertools.chain.from_iterable([list(i.word) for i in combined_datalist]))\n",
        "values_=list(itertools.chain.from_iterable([list(i.values_) for i in combined_datalist]))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwwbAhMpxv9u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "values_=[' '.join(s) for s in [list(re.findall(r'[\\d\\.]{1,8}',str(i))) for i in values_]]"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdcIBwbQsq2W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "ef373514-7526-43b4-ea77-cfaeee764f1a"
      },
      "source": [
        "print(values_[0])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.038194 0.24487 0.72812 0.39961 0.083172 0.043953 0.39141 0.3344 0.57545 0.087459 0.28787 0.06731 0.30906 0.26384 0.13231 0.20757 0.33395 0.33848 0.31743 0.48336 0.1464 0.37304 0.34577 0.052041 0.44946 0.46971 0.02628 0.54155 0.15518 0.14107 0.039722 0.28277 0.14393 0.23464 0.31021 0.086173 0.20397 0.52624 0.17164 0.082378 0.71787 0.41531 0.20335 0.12763 0.41367 0.55187 0.57908 0.33477 0.36559 0.54857 0.062892 0.26584 0.30205 0.99775 0.80481 3.0243 0.01254 0.36942 2.2167 0.72201 0.24978 0.92136 0.034514 0.46745 1.1079 0.19358 0.074575 0.23353 0.052062 0.22044 0.057162 0.15806 0.30798 0.41625 0.37972 0.15006 0.53212 0.2055 1.2526 0.071624 0.70565 0.49744 0.42063 0.26148 1.538 0.30223 0.073438 0.28312 0.37104 0.25217 0.016215 0.017099 0.38984 0.87424 0.72569 0.51058 0.52028 0.1459 0.8278 0.27062\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16DtcByKkmEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed_index=dict(zip(words_,values_))"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "is43I3f5uCt8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "3f97ec95-9cc2-4469-fd6b-beee1755cc88"
      },
      "source": [
        "word_tokenizer = Tokenizer()\n",
        "word_tokenizer.fit_on_texts(data3.no_stopwords_stemmed)\n",
        "\n",
        "embedded_skill=word_tokenizer.texts_to_sequences(data3.no_stopwords_stemmed)\n",
        "\n",
        "vocab_length = len(word_tokenizer.word_index) + 1\n",
        "\n",
        "embedding_matrix = zeros((vocab_length, 100))\n",
        "for word, index in word_tokenizer.word_index.items():\n",
        "    embedding_vector = embed_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[index] = embedding_vector"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-28010ed544f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0membedding_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membed_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0membedding_vector\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0membedding_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '0.75068 0.32913 0.031241 0.57064 0.37469 1.0634 0.76923 0.41845 0.35906 0.8075 1.0689 0.8981 0.61308 0.23257 0.053158 1.188 0.40813 0.4509 0.56694 0.18971 0.60499 0.46727 0.43205 0.64668 0.55169 0.24941 0.71557 0.59479 0.072287 0.008350 2 0.46712 0.38149 0.67214 0.15017 0.45906 0.84152 1.161 0.20258 0.45916 0.67642 0.48139 0.37672 0.10056 0.78212 0.93747 0.21828 0.31398 0.2366 0.25032 0.35674 0.047259 1.1123 0.28031 1.2197 0.7633 0.87313 0.084615 0.13935 2.5794 0.49056 0.35126 0.91263 0.31829 1.2081 0.42488 0.066665 0.657 0.11055 0.76495 0.84925 0.43194 1.5505 0.0832 0.30108 0.81387 0.02638 0.28665 0.70617 1.3116 0.51475 0.33542 0.31254 0.018876 0.5439 0.85285 0.34816 0.95368 0.7165 0.29994 0.23561 0.49212 0.13382 0.46441 0.13664 0.43676 0.87997 0.91403 0.003703 5 0.57089 0.95073'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UZw7hsEatrG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "561f8597-c93a-4e1e-a31a-558f8a7be5a1"
      },
      "source": [
        "\n",
        "        \n",
        "length_long_sentence=max(len_sent)\n",
        "\n",
        "padded_sentences = pad_sequences(embedded_skill, length_long_sentence, padding='post')\n",
        "\n",
        "validation_split=.2\n",
        "indices=np.arange(np.array(padded_sentences,dtype=object).shape[0])\n",
        "np.random.shuffle(indices)   \n",
        "\n",
        "data_rand=padded_sentences[indices]\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "labe=[str(i).replace('.xls','') for i in data3.occ_group]\n",
        "\n",
        "labels_encoded=le.fit(labe)\n",
        "labels_=le.transform(labe)\n",
        "\n",
        "labels_rand=np.array(labels_)[indices]\n",
        "\n",
        "val_sample=int(validation_split * data3.shape[0])\n",
        "X_train=data_rand[:-val_sample]\n",
        "y_train=labels_rand[:-val_sample]\n",
        "X_test=data_rand[-val_sample:]\n",
        "y_test=labels_rand[-val_sample:]\n",
        "\n",
        "x_train = torch.tensor(X_train, dtype=torch.long)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "x_cv = torch.tensor(X_test, dtype=torch.long)\n",
        "y_cv = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "train = torch.utils.data.TensorDataset(x_train, y_train)\n",
        "valid = torch.utils.data.TensorDataset(x_cv, y_cv)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size=70, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid, batch_size=70, shuffle=False)\n",
        "class BiLSTM(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(BiLSTM, self).__init__()\n",
        "        self.hidden_size = 164\n",
        "        drp = 0.4\n",
        "        n_classes = len(le.classes_)\n",
        "        self.embedding = nn.Embedding(max_features, embed_size)\n",
        "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
        "        self.embedding.weight.requires_grad = True\n",
        "        self.lstm = nn.LSTM(embed_size, self.hidden_size, bidirectional=True, batch_first=True)\n",
        "        self.linear = nn.Linear(self.hidden_size*4 , 164)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.out = nn.Linear(164, n_classes)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        h_embedding = self.embedding(x)\n",
        "        h_lstm, _ = self.lstm(h_embedding)\n",
        "        avg_pool = torch.mean(h_lstm, 1)\n",
        "        max_pool, _ = torch.max(h_lstm, 1)\n",
        "        conc = torch.cat(( avg_pool, max_pool), 1)\n",
        "        conc = self.relu(self.linear(conc))\n",
        "        out = self.out(conc)\n",
        "        return out\n",
        "        \n",
        "        \n",
        "embed_size=100\n",
        "max_features=vocab_length\n",
        "n_epochs = 7\n",
        "model = BiLSTM()\n",
        "loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
        "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=0.002, weight_decay=0)\n",
        "model.cpu()\n",
        "\n",
        "\n",
        "val_preds1=[]\n",
        "X1=[]\n",
        "Y1=[]\n",
        "ind1=[]\n",
        "val_loss1=[]\n",
        "output=[]\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    start_time = time.time()\n",
        "    \n",
        "    model.train()\n",
        "    avg_loss = 0.  \n",
        "    for i, (x_batch, y_batch) in enumerate(train_loader):\n",
        "        \n",
        "        y_pred = model(x_batch)\n",
        "       \n",
        "        loss = loss_fn(y_pred, y_batch)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        avg_loss += loss.item() / len(train_loader)\n",
        "    \n",
        "    \n",
        "    model.eval()        \n",
        "    avg_val_loss = 0.\n",
        "    val_preds = np.zeros((len(x_cv),len(le.classes_)))\n",
        "    X=np.zeros((len(x_cv),length_long_sentence))\n",
        "    Y=np.zeros((len(x_cv),))\n",
        "    ind=np.zeros((len(x_cv),))\n",
        "    val_loss=np.zeros((len(x_cv),))\n",
        "    \n",
        "    for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
        "        \n",
        "        y_pred = model(x_batch).detach()\n",
        "        avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
        "        \n",
        "        val_preds[i * 70:(i+1) * 70] =F.sigmoid(y_pred).cpu().numpy()\n",
        "        X[i * 70:(i+1) * 70]=x_batch.cpu().numpy()\n",
        "        Y[i * 70:(i+1) * 70]=y_batch.cpu().numpy()\n",
        "        ind[i * 70:(i+1) * 70]=i\n",
        "        val_loss[i * 70:(i+1) * 70]=avg_val_loss\n",
        "        \n",
        "    val_preds1.append(val_preds)\n",
        "    X1.append(X)\n",
        "    Y1.append(Y)\n",
        "    ind1.append(ind)\n",
        "    val_loss1.append(val_loss)\n",
        "    \n",
        "    val_accuracy = sum(val_preds.argmax(axis=1)==y_test)/len(y_test)\n",
        "    \n",
        "    \n",
        "    \n",
        "    elapsed_time = time.time() - start_time \n",
        "    output.append('Epoch {}/{} \\t loss={:.4f} \\t val_loss={:.4f}  \\t val_acc={:.4f}  \\t time={:.2f}s'.format(\n",
        "                epoch + 1, n_epochs, avg_loss, avg_val_loss, val_accuracy, elapsed_time))\n",
        "                \n",
        "output_df=pd.DataFrame([i.split('\\t') for i in output])\n",
        "output_df.columns=['epoch','loss','validation_loss','validation_accuracy','time']\n",
        "\n",
        "Y1_s=[int(i) for i in Y1[3]]\n",
        "pred=list([i.argmax() for i in val_preds1[3]])\n",
        "\n",
        "df_encoded=pd.concat([pd.Series(Y1_s, name='actual_class'), \n",
        "             pd.Series(pred, name='predicted_class'),\n",
        "             pd.Series([list(i) for i in X1[3]], name='text')], axis=1)\n",
        "             \n",
        "             \n",
        "word_encoding=word_tokenizer.word_index\n",
        "word_decoding=dict(zip(list(word_encoding.values()), list(word_encoding.keys())))\n",
        "word_decoding[0]='None'\n",
        "\n",
        "skill_decoding=dict(zip(list(labels_), list(labe)))\n",
        "\n",
        "text2=[]\n",
        "for i in df_encoded.text:\n",
        "    text2.append([word_decoding[p] for p in i])\n",
        "    \n",
        "text2=[i for i in text2 if i!='None']\n",
        "df_encoded['text2']=pd.Series(text2)\n",
        "df_encoded['actual_class_']=[skill_decoding[i] for i in df_encoded['actual_class']]\n",
        "df_encoded['predicted_class_']=[skill_decoding[i] for i in df_encoded['predicted_class']]\n",
        "df_encoded_=df_encoded[['actual_class_','predicted_class_','text2']].reset_index()\n",
        "\n",
        "df_encoded_.columns=['id', 'actual_class_', 'predicted_class_', 'words']\n",
        "\n",
        "df_encoded_            \n",
        "             \n",
        "\n",
        "     \n",
        "\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-468f647073f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0membedding_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membed_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0membedding_vector\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0membedding_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mlength_long_sentence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen_sent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot copy sequence with size 200 to array axis with dimension 102"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWcKun6iatpQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}